{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AphroditeScrape.ipynb","provenance":[],"authorship_tag":"ABX9TyMuKrV0fUT8O+CRMLkZ4R/U"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AjmaSc78TVWu"},"source":["Web scraping is the process of gathering information from the Internet.\n","\n","The Python libraries requests and Beautiful Soup are powerful tools for the job."]},{"cell_type":"code","metadata":{"id":"XVNtwhooST-I"},"source":["import requests\n","\n","aphrodite_URL = 'http://olympus.realpython.org/profiles/aphrodite'\n","page = requests.get(aphrodite_URL)\n","print(page.status_code)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tobwAlVXU-oN"},"source":["After running our request, we get a Response object. This object has a status_code property, which indicates if the page was downloaded successfully"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSVVEcJnVPhO","executionInfo":{"status":"ok","timestamp":1607548089404,"user_tz":420,"elapsed":657,"user":{"displayName":"Rahul Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpyn8cxrWTYfpuNDHdxoQmWTSE2MY8Vnu5xvra=s64","userId":"18024682597819105566"}},"outputId":"4fd28be2-6884-42cc-e31f-7ddc83628946"},"source":["print(page.content)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["b'<html>\\n<head>\\n<title>Profile: Aphrodite</title>\\n</head>\\n<body bgcolor=\"yellow\">\\n<center>\\n<br><br>\\n<img src=\"/static/aphrodite.gif\" />\\n<h2>Name: Aphrodite</h2>\\n<br><br>\\nFavorite animal: Dove\\n<br><br>\\nFavorite color: Red\\n<br><br>\\nHometown: Mount Olympus\\n</center>\\n</body>\\n</html>\\n'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iDhZjo2BVejK"},"source":["We can use the BeautifulSoup library to parse this document, and extract the text"]},{"cell_type":"code","metadata":{"id":"f-Od20muVhAt","executionInfo":{"status":"ok","timestamp":1607548161711,"user_tz":420,"elapsed":680,"user":{"displayName":"Rahul Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpyn8cxrWTYfpuNDHdxoQmWTSE2MY8Vnu5xvra=s64","userId":"18024682597819105566"}}},"source":["from bs4 import BeautifulSoup\n","soup = BeautifulSoup(page.content, 'html.parser')"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Na4w2pgYVqpg"},"source":["We can now print out the HTML content of the page, formatted nicely, using the prettify method on the BeautifulSoup object"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqmmW7ENVtMx","executionInfo":{"status":"ok","timestamp":1607548213920,"user_tz":420,"elapsed":644,"user":{"displayName":"Rahul Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpyn8cxrWTYfpuNDHdxoQmWTSE2MY8Vnu5xvra=s64","userId":"18024682597819105566"}},"outputId":"1b939073-2a31-4205-caa0-e2821285af5a"},"source":["print(soup.prettify())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["<html>\n"," <head>\n","  <title>\n","   Profile: Aphrodite\n","  </title>\n"," </head>\n"," <body bgcolor=\"yellow\">\n","  <center>\n","   <br/>\n","   <br/>\n","   <img src=\"/static/aphrodite.gif\"/>\n","   <h2>\n","    Name: Aphrodite\n","   </h2>\n","   <br/>\n","   <br/>\n","   Favorite animal: Dove\n","   <br/>\n","   <br/>\n","   Favorite color: Red\n","   <br/>\n","   <br/>\n","   Hometown: Mount Olympus\n","  </center>\n"," </body>\n","</html>\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O9RoTbfiWDTD"},"source":["soup.children\n","\n","list(soup.children)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bbQ4VxxbWGST"},"source":["children returns a list generator, so we need to call the list function on it"]},{"cell_type":"markdown","metadata":{"id":"WgvzZumqXNhs"},"source":["The Tag object allows us to navigate through an HTML document, and extract other tags and text."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3E5dMFPWI2x","executionInfo":{"status":"ok","timestamp":1607548543551,"user_tz":420,"elapsed":710,"user":{"displayName":"Rahul Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpyn8cxrWTYfpuNDHdxoQmWTSE2MY8Vnu5xvra=s64","userId":"18024682597819105566"}},"outputId":"fbdcc686-343b-4209-de98-d3882ba10e00"},"source":["[type(item) for item in list(soup.children)]"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[bs4.element.Tag, bs4.element.NavigableString]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"5fk3hHjSX6uR"},"source":["We can now select the html tag and its children by taking the first item in the list\n","\n","Now, we can find the children inside the html tag"]},{"cell_type":"code","metadata":{"id":"XW-XoP4YXOou"},"source":["html = list(soup.children)[0]\n","\n","print(html)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D-z2h3fnYBON"},"source":["list(html.children)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVdsnYMHaCZG"},"source":["body = list(html.children)[3]\n","print(body.get_text())\n","\n","print(body)\n","list(body.children)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aDiD4DEtds1c"},"source":["Want to find the first instance of a tag, you can use the find method, which will return a single BeautifulSoup object"]},{"cell_type":"code","metadata":{"id":"puETC2EPdlPB"},"source":["soup.find('h2')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dKsITnceVSa"},"source":["find_all returns a list, so we’ll have to loop through, or use list indexing, it to extract text:"]},{"cell_type":"code","metadata":{"id":"5qS7c86ad0Ht"},"source":["soup.find_all('h2')[0].get_text()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGI0L-wafHnU","executionInfo":{"status":"ok","timestamp":1607550672535,"user_tz":420,"elapsed":567,"user":{"displayName":"Rahul Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpyn8cxrWTYfpuNDHdxoQmWTSE2MY8Vnu5xvra=s64","userId":"18024682597819105566"}}},"source":["def getAndParseURL(url):\n","    result = requests.get(url)\n","    soup = BeautifulSoup(result.text, 'html.parser')\n","    return(soup)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGXsx4eKfKme","executionInfo":{"status":"ok","timestamp":1607551742839,"user_tz":420,"elapsed":634,"user":{"displayName":"Rahul Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpyn8cxrWTYfpuNDHdxoQmWTSE2MY8Vnu5xvra=s64","userId":"18024682597819105566"}},"outputId":"8cd274a5-d0a3-41db-a1ee-1d7096d35061"},"source":["dq_ids_classes_url = \"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\"\n","\n","simple_ex_soup = getAndParseURL(dq_ids_classes_url)\n","simple_ex_soup"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<html>\n","<head>\n","<title>A simple example page</title>\n","</head>\n","<body>\n","<div>\n","<p class=\"inner-text first-item\" id=\"first\">\n","                First paragraph.\n","            </p>\n","<p class=\"inner-text\">\n","                Second paragraph.\n","            </p>\n","</div>\n","<p class=\"outer-text first-item\" id=\"second\">\n","<b>\n","                First outer paragraph.\n","            </b>\n","</p>\n","<p class=\"outer-text\">\n","<b>\n","                Second outer paragraph.\n","            </b>\n","</p>\n","</body>\n","</html>"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"Vv06aUC8gdll"},"source":["find_all returns a list, so we’ll have to loop through, or use list indexing, it to extract text:"]},{"cell_type":"code","metadata":{"id":"O5W-8Ggwg1Zr"},"source":["simple_ex_soup.find_all('p')[0].get_text()\n","\n","for x in simple_ex_soup.findAll(\"p\"):\n","  print(x.get_text())\n","\n","simple_ex_soup.find_all('p', class_='outer-text')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Id3WcEKSlCct"},"source":["simple_ex_soup.find_all(class_='outer-text')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sI-jVkBLlojw"},"source":["simple_ex_soup.find_all(id=\"first\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nAnzj3uEmV6x"},"source":["BeautifulSoup objects support searching a page via CSS selectors using the select method. We can use CSS selectors to find all the p tags in our page that are inside of a div like this:"]},{"cell_type":"code","metadata":{"id":"G8i5nJy6l-rn"},"source":["simple_ex_soup.select(\"div p\")"],"execution_count":null,"outputs":[]}]}